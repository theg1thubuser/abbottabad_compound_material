# Abbottabad Compound Material

Welcome to the interactive exploration of the Abbottabad Compound Material, a collection of images seized by the CIA during the 2011 raid on Osama bin Laden's compound in Pakistan. This app provides a unique window into this historical dataset, allowing you to browse and filter images interactively.

**Disclaimer**: The authors are not affiliated, associated, authorized, endorsed by, or in any way officially connected with any of the displayed or mentioned persons, organizations, or states. All views and opinions expressed do not reflect the personal views or opinions of the authors.

## Overview

This application aims to aid in the analysis and understanding of the images found in the Abbottabad compound. It leverages OpenAI's CLIP model to classify images based on predefined categories and provides tools to filter images by classification scores, dates, and camera metadata.

### Features

- **Image Classification Results**: Filter and view images according to their classification scores for specific categories.
- **Image Metadata Insights**: Analyze images based on metadata such as capture date and camera information.
- **Interactive Exploration**: Use sidebars to select categories, set thresholds, and specify date ranges for dynamic updates.

### Usage

1. **Select Category**: Choose a keyword category from the sidebar dropdown.
2. **Set Threshold**: Adjust the threshold slider to filter images based on classification scores.
3. **View Images**: Browse the grid of images that meet the criteria.
4. **Filter by Date**: Specify a start and end date to filter images based on capture dates.
5. **Display Metadata**: Toggle to show camera make, model, and capture date information.

### Important Notes - Content Warning

- The material may contain content that is offensive or emotionally disturbing.
- All images on this website are featured in the November 2017 Release of the Abbottabad Compound Material. [CIA library with all material](https://www.cia.gov/library/abbottabad-compound/index.html) (last accessed: 6 Jun 24)
- Before you start exploring, please note that the material in this file collection may contain content that is offensive and/or emotionally disturbing. This material may not be suitable for all ages. Please view it with discretion.
- Prior to accessing this file collection, please understand that this material was seized from a terrorist organization by the US Central Intelligence Agency.

### Access the App

You can explore the app using the following link: [Abbottabad Compound Material](https://abbottabadcompoundmaterial.streamlit.app/)

### References

- **CIA November 2017 Release**: [CIA library with all material](https://www.cia.gov/library/abbottabad-compound/index.html) (last accessed: 6 Jun 24)

### About CLIP

CLIP (Contrastive Languageâ€“Image Pretraining) is a model developed by OpenAI that bridges the gap between computer vision and natural language processing. It classifies images based on textual descriptions and has demonstrated versatility in various tasks such as zero-shot classification and object detection.

For more details on how the CLIP model works and its classification process, click the expander in the app.

_Last edited: 6 Jun 25 by theg1thubuser_


https://abbottabadcompoundmaterial.streamlit.app/
